<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Biography Page</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="bio-container">
        <img src="profile.jpg" alt="Profile Image" class="profile-img">
        <div class="bio-text">
            <p>Hi! Iâ€™m Aura, a Computer Science PhD candidate at the University of California, Davis. My research revolves around MultiModal Foundation Models and Agentic Workflows, with a special focus on enhancing decision-making systems.</p>
            <p> During my PhD, I completed an internship as an Applied Scientist at Amazon with the Rufus team, focusing on Multimodality. I also spent a year at UC Berkeley as part of the UC Exchange Program. I have actively contributed to various machine learning projects in both academia and industry. </p>
            <p> I was involved in California Transportation projects for three years, developing an AI-based TMA truck targeted warning messaging system and enhancing vehicle detection technologies to improve safety and reduce accidents in highway work zones, while also working on ADA Ramp Compliance using Point Cloud and Image Processing. At Munich Re, I designed and implemented an efficient agentic MLLM workflow for automated report generation. I also developed a system for RAG-based retrieval, document question answering, and summarization. Additionally, I designed ads-related retrieval based on search and user history and developed an RL-based reward system based on human feedback for Myket (Android App Store).</p>
            <p> Additionally, I have led over 20 teams of graduate students in various industrial machine learning projects, focusing on addressing complex industrial challenges through innovative, state-of-the-art methods. </p>
        </div>
        <div class="links">
            <a href="https://www.linkedin.com/in/arefehyavary/" target="https://www.linkedin.com/in/arefehyavary/">LinkedIn</a>
            <a href="https://scholar.google.com/citations?user=MyHlWIMAAAAJ&hl=en" target="https://scholar.google.com/citations?user=MyHlWIMAAAAJ&hl=en">Google Scholar</a>
            <a href="https://github.com/SJ9VRF" target="https://github.com/SJ9VRF">GitHub</a>
        </div>
    </div>


    <!-- Section Header for Selected Projects -->
    <h2 class="section-header">Selected Projects</h2>
    
    <!-- Additional squares -->
    <div class="mini-bio-container">
        <img src="Realator.png" alt="Image Description" class="mini-profile-img">
        <div class="content">
            <h3>Realator</h3>
            <p>A simulator for world model building integrates foundation models with RL to simulate and predict real-world scenarios. It incorporates physical interactions and physics intelligence to learn environmental dynamics, enabling accurate decision-making and adaptive behaviors in real environments.</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>


    
    <!-- Repeat for each additional square as needed, changing src, title, and description accordingly -->

    <div class="mini-bio-container">
        <img src="call.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>Call</h3>
            <p>A Communication Tunnel between agents enables secure, interpretable info exchange, enhancing collaboration, decision-making, and safety. With foundation models, RL feedback, and reward systems, multi-agent LLMs adapt, align to human goals, and optimize task performance iteratively.</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>


    <div class="mini-bio-container">
        <img src="helpinghands.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>Helping-Hands</h3>
            <p>This study uses Vision-Language Models (VLMs) to interpret structured assembly maps for robots in long-horizon tasks. LLMs convert visual assembly steps into textual instructions, validating consistency with prior steps, enabling efficient robotic execution with minimal feedback.</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>
  
    <div class="mini-bio-container">
        <img src="DiffuNet.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>DiffuNet</h3>
            <p>Diffusion models refine random noise into structured outputs, aiding neural architecture design by learning a reverse denoising process. They encode architectures as graphs or sequences, generating diverse samples that meet performance constraints. This advances NAS by automating scalable, efficient designs.</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>        
    </div>   
    
    <div class="mini-bio-container">
        <img src="ActPix2Pix.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>ActPix2Pix</h3>
            <p>World Model Building Using Physical Action Variant</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>      
    
    <div class="mini-bio-container">
        <img src="TaskMasters.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>TaskMasters</h3>
            <p>Mastering Natural Language for Robot Ears for Superior Task Execution</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>

    <div class="mini-bio-container">
        <img src="Binding4WM.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>MM4WM</h3>
            <p>Modality Tunning for World Model</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>

    <div class="mini-bio-container">
        <img src="BindingWorldModel.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>BindingWorldModel</h3>
            <p>MultiModal Binding for World Modeling</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>

    <div class="mini-bio-container">
        <img src="TransReward.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>TransReward</h3>
            <p>Exploring multi-robot, multi-task transfer through reward compensation and reinforcement learning (RL), we developed a scalable framework enabling robots to learn from one another. Using RL, we optimized policy adaptation for varying dynamics, morphologies, and resource constraints. Our approach integrates reward compensation to enhance RL exploration and exploitation, enabling efficient task and dynamics transfer. Co-training strategies further refine policy updates for source and target robots, ensuring mutual learning and convergence. This novel RL-based framework demonstrates improved performance in multi-robot environments, emphasizing data efficiency and adaptability to resource-limited tasks.</p>
        </div>

        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>


    <div class="mini-bio-container">
        <img src="AdFlux.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>AdFlux Engine</h3>
            <p>AdFlux Engine is a Foundation model for Advertisement Simulation, predicting user behavior (clicks/views) from historical data. Utilizing advanced models like LAVA, Decision Transformers, Gato, and MuZero, it optimizes ad placements and boosts user engagement. Built for scalability, it integrates NLP, RL, and RLHF techniques.</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF/AdFlux-Engine" target="_blank">GitHub</a>
        </div>
    </div>


    <div class="mini-bio-container">
        <img src="verillm.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>TruthSeeker LLMs</h3>
            <p>LLMs for Information Verification</p>
        </div>

        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>  

    <div class="mini-bio-container">
        <img src="AdFlux Agentic Engine.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>AdFlux Agentic Engine</h3>
            <p>Agentic advertising workflow leveraging LLMs and advertising foundation models to optimize digital advertising. It combines general advertising processes with specific steps to deliver highly relevant ads that are well-timed, ensuring continuous optimization for user engagement and advertiser conversion goals</p>
        </div>

        <div class="links">
            <a href="https://github.com/SJ9VRF/AdFlux-Agentic-Engine" target="_blank">GitHub</a>
        </div>
    </div>

    <div class="mini-bio-container">
        <img src="LLM-COMMUNICATORS.png" alt="Image Description" class="mini-profile-img">
        <div>
            <h3>LLM Communicators</h3>
            <p>llms are great communicators: enhancing llm capabilities via communication</p>
        </div>
        <div class="links">
            <a href="https://github.com/SJ9VRF" target="_blank">GitHub</a>
        </div>
    </div>

</body>
</html>
